import os
import zipfile
import re
import shutil
from PIL import Image, ImageDraw, ImageFont
from math import ceil
from docx import Document
from docx.oxml.ns import qn

# ==========================================
# æ¨¡å— 1: è¾…åŠ©å·¥å…· (æ’åºä¸å›¾åƒå¤„ç†)
# ==========================================

def natural_sort_key(s):
    """è‡ªç„¶æ’åºï¼šç¡®ä¿ image2 åœ¨ image10 ä¹‹å‰"""
    return [int(text) if text.isdigit() else text.lower()
            for text in re.split(r'(\d+)', s)]

def process_image_for_ai(img_path):
    """
    å›¾åƒé¢„å¤„ç†æ ¸å¿ƒï¼š
    1. ä¿®æ­£é€æ˜èƒŒæ™¯ (è§£å†³é»‘ç™½å›¾åœ¨ AI é¢å‰'éšèº«'çš„é—®é¢˜)
    2. è½¬æ¢ä¸º RGB
    """
    try:
        img = Image.open(img_path)
        # å¦‚æœæœ‰é€æ˜é€šé“ (RGBA) æˆ– P æ¨¡å¼ï¼Œè½¬æ¢ä¸ºç™½è‰²èƒŒæ™¯çš„ RGB
        if img.mode in ('RGBA', 'LA') or (img.mode == 'P' and 'transparency' in img.info):
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            # ä½¿ç”¨ alpha é€šé“ä½œä¸ºæ©ç è¿›è¡Œåˆæˆ
            background.paste(img, mask=img.split()[3]) 
            return background
        else:
            return img.convert('RGB')
    except Exception as e:
        print(f"Warning: å›¾åƒå¤„ç†å‡ºé”™ {img_path} - {e}")
        return None

def create_visual_reference_pdf(image_files, media_dir, output_pdf_path):
    """ç”Ÿæˆè§†è§‰å‚è€ƒ PDF (å·²å‡çº§ï¼šå¢åŠ é€æ˜åº¦å¤„ç†)"""
    pdf_pages = []
    page_width, page_height = 595, 842 # A4
    margin = 50
    try:
        font = ImageFont.truetype("arial.ttf", 24)
    except:
        font = ImageFont.load_default()

    for filename in image_files:
        img_path = os.path.join(media_dir, filename)
        
        # --- å‡çº§ç‚¹ï¼šè°ƒç”¨é¢„å¤„ç†å‡½æ•° ---
        src_img = process_image_for_ai(img_path)
        if src_img is None: continue

        # åˆ›å»ºé¡µé¢
        page = Image.new('RGB', (page_width, page_height), (255, 255, 255))
        draw = ImageDraw.Draw(page)
        
        # å†™å…¥ ID
        text = f"ID: {filename}"
        bbox = draw.textbbox((0, 0), text, font=font)
        text_w = bbox[2] - bbox[0]
        text_h = bbox[3] - bbox[1]
        draw.text(((page_width - text_w) / 2, margin), text, fill=(0, 0, 0), font=font)
        
        # ç¼©æ”¾å›¾ç‰‡
        max_img_w = page_width - 2 * margin
        max_img_h = page_height - 3 * margin - text_h
        src_img.thumbnail((max_img_w, max_img_h), Image.Resampling.LANCZOS)
        
        # å±…ä¸­ç²˜è´´
        img_x = int((page_width - src_img.width) / 2)
        img_y = int(margin + text_h + 20)
        page.paste(src_img, (img_x, img_y))
        
        pdf_pages.append(page)

    if pdf_pages:
        pdf_pages[0].save(output_pdf_path, "PDF", resolution=100.0, save_all=True, append_images=pdf_pages[1:])
        print(f"   --> ç”Ÿæˆè§†è§‰å‚è€ƒ: {os.path.basename(output_pdf_path)}")

# ==========================================
# æ¨¡å— 2: éª¨æ¶æå–å™¨ (Text Skeleton)
# ==========================================

class SkeletonExtractor:
    def __init__(self, docx_path):
        self.docx_path = docx_path
        self.doc = Document(docx_path)
        self.rels = self.doc.part.rels
        self.rId_to_filename = {}
        self._map_rels()

    def _map_rels(self):
        """
        å»ºç«‹ rId -> å®é™…æ–‡ä»¶åçš„æ˜ å°„è¡¨
        Word å†…éƒ¨é€šè¿‡ rId (å¦‚ rId7) å¼•ç”¨å›¾ç‰‡ï¼Œè€Œä¸æ˜¯ç›´æ¥ç”¨æ–‡ä»¶åã€‚
        """
        for rel in self.rels.values():
            if "image" in rel.target_ref:
                # target_ref é€šå¸¸æ˜¯ 'media/image1.png'
                filename = os.path.basename(rel.target_ref)
                self.rId_to_filename[rel.rId] = filename

    def extract_to_markdown(self):
        """
        éå†æ–‡æ¡£æ®µè½ï¼Œç”Ÿæˆå¸¦ <<IMG_xxx>> é”šç‚¹çš„ Markdown
        """
        md_lines = []
        
        for para in self.doc.paragraphs:
            text = para.text.strip()
            style_name = para.style.name

            # 1. ç®€å•çš„æ ·å¼æ˜ å°„
            prefix = ""
            if style_name.startswith('Heading 1'): prefix = "# "
            elif style_name.startswith('Heading 2'): prefix = "## "
            elif style_name.startswith('Heading 3'): prefix = "### "
            elif "List" in style_name: prefix = "- "
            
            # 2. æ£€æŸ¥æ®µè½ä¸­çš„ XML æ˜¯å¦åŒ…å«å›¾ç‰‡å¼•ç”¨ (blip)
            # è¿™æ˜¯ä¸€ä¸ªåº•å±‚æ“ä½œï¼Œå¯»æ‰¾ <a:blip r:embed="rIdX">
            if 'graphicData' in para._p.xml:
                for rId, filename in self.rId_to_filename.items():
                    # å¦‚æœè¯¥æ®µè½çš„ XML æºç ä¸­åŒ…å«è¿™ä¸ª rId
                    if f'r:embed="{rId}"' in para._p.xml:
                        # æ’å…¥é”šç‚¹ (è¿™æ˜¯ç»™ AI çœ‹çš„é€»è¾‘æŒ‡é’ˆ)
                        md_lines.append(f"\n> **[æ’å…¥å›¾ç‰‡]** ID: <<{filename}>>\n")
            
            if text:
                md_lines.append(f"{prefix}{text}")
                
        return "\n\n".join(md_lines)

# ==========================================
# ä¸»ç¨‹åº
# ==========================================

def main(input_docx, output_folder):
    if not os.path.exists(input_docx):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {input_docx}")
        return

    doc_name = os.path.splitext(os.path.basename(input_docx))[0]
    base_output_dir = os.path.join(output_folder, doc_name)
    media_dir = os.path.join(base_output_dir, "media_source")
    visual_ref_dir = os.path.join(base_output_dir, "visual_refs")
    
    # æ¸…ç†é‡å»ºç›®å½•
    if os.path.exists(base_output_dir):
        shutil.rmtree(base_output_dir)
    os.makedirs(media_dir)
    os.makedirs(visual_ref_dir)

    print(f"ğŸš€ å¼€å§‹æ‹†è§£: {doc_name}")

    # Step 1: ç‰©ç†æå–å›¾ç‰‡ (ä½¿ç”¨ ZipFile ç¡®ä¿æ— æŸ)
    print("   ...æ­£åœ¨è§£å‹åª’ä½“èµ„æº")
    with zipfile.ZipFile(input_docx, 'r') as z:
        for file_info in z.infolist():
            if file_info.filename.startswith('word/media/'):
                z.extract(file_info, media_dir)
    
    # ç§»åŠ¨æ–‡ä»¶åˆ° media_source æ ¹ç›®å½•å¹¶æ¸…ç†ç©ºæ–‡ä»¶å¤¹
    actual_media_dir = os.path.join(media_dir, 'word', 'media')
    if os.path.exists(actual_media_dir):
        files = os.listdir(actual_media_dir)
        valid_exts = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'}
        image_files = [f for f in files if os.path.splitext(f)[1].lower() in valid_exts]
        image_files.sort(key=natural_sort_key) # æ’åº

        for f in image_files:
            shutil.move(os.path.join(actual_media_dir, f), os.path.join(media_dir, f))
        shutil.rmtree(os.path.join(media_dir, 'word')) # åˆ é™¤ç©ºå£³
    else:
        image_files = []
        print("   âš ï¸ æ–‡æ¡£ä¸­æœªå‘ç°å›¾ç‰‡")

    # Step 2: ç”Ÿæˆè§†è§‰å‚è€ƒ PDF
    if image_files:
        print("   ...æ­£åœ¨ç”Ÿæˆè§†è§‰å‚è€ƒ PDF")
        CHUNK_SIZE = 50 # å‡å°ä¸€ç‚¹ï¼Œé˜²æ­¢ PDF è¿‡å¤§
        total_chunks = ceil(len(image_files) / CHUNK_SIZE)
        for i in range(total_chunks):
            chunk = image_files[i*CHUNK_SIZE : (i+1)*CHUNK_SIZE]
            pdf_path = os.path.join(visual_ref_dir, f"{doc_name}_VisualRef_Part{i+1}.pdf")
            create_visual_reference_pdf(chunk, media_dir, pdf_path)

    # Step 3: æå–æ–‡æœ¬éª¨æ¶ (Markdown)
    print("   ...æ­£åœ¨ç”Ÿæˆæ–‡æœ¬éª¨æ¶ (Markdown)")
    extractor = SkeletonExtractor(input_docx)
    skeleton_md = extractor.extract_to_markdown()
    
    skeleton_path = os.path.join(base_output_dir, "skeleton.md")
    with open(skeleton_path, "w", encoding="utf-8") as f:
        f.write(f"# æ–‡æ¡£éª¨æ¶: {doc_name}\n\n")
        f.write("> æ­¤æ–‡æ¡£ç”± AI è‡ªåŠ¨æ‹†è§£ã€‚<<IMG_...>> ä¸ºå›¾ç‰‡å ä½ç¬¦ã€‚\n\n")
        f.write(skeleton_md)

    print(f"âœ… ä»»åŠ¡å®Œæˆ! è¾“å‡ºç›®å½•: {base_output_dir}")
    print(f"   -> éª¨æ¶æ–‡ä»¶: skeleton.md")
    print(f"   -> å›¾ç‰‡èµ„æº: media_source/")

if __name__ == "__main__":
    # ä¿®æ”¹è¿™é‡Œä¸ºä½ çš„æ–‡ä»¶å
    input_file = "input.docx" 

    main(input_file, "./pipeline_output")
